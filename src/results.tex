\section{Results}

The evaluation system implements COCO metrics including precision and recall at IoU threshold 0.5, mean average precision (mAP) at IoU 0.5, and mAP across IoU thresholds 0.5-0.95.

The results of the developed model and the YOLO models trained in SH-17 paper are displayed in Table 1 which comes from the SH-17 repository ().

The top performing model is bolded.

\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|}
    \hline
        Model & Params (M) & Images & Instances & P (\%) & R (\%) & mAP50 (\%) & mAP50-95 (\%) \\ \hline
        HOG-SVM & - & 1620 & 15358 & 3.3 & 12.2 & 1.1 & 1.0 \\ \hline
        Yolo-8-n & 3.2 & 1620 & 15358 & 67.5 & 53.6 & 58.0 & 36.6 \\ \hline
        Yolo-8-s & 11.2 & 1620 & 15358 & 81.5 & 55.7 & 63.7 & 41.7 \\ \hline
        Yolo-8-m & 25.9 & 1620 & 15358 & 77.1 & 60.5 & 66.6 & 45.7 \\ \hline
        Yolo-8-l & 43.7 & 1620 & 15358 & 76.7 & 62.9 & 68.0 & 47.0 \\ \hline
        Yolo-8-x & 68.2 & 1620 & 15358 & 77.1 & 63.1 & 69.3 & 47.2 \\ \hline
        Yolo-9-t & 2.0 & 1620 & 15358 & 75.0 & 52.6 & 58.5 & 37.5 \\ \hline
        Yolo-9-s & 7.2 & 1620 & 15358 & 73.6 & 60.2 & 65.3 & 42.9 \\ \hline
        Yolo-9-m & 20.1 & 1620 & 15358 & 77.4 & 62.0 & 68.6 & 46.5 \\ \hline
        Yolo-9-c & 25.5 & 1620 & 15358 & 79.6 & 60.8 & 67.7 & 46.5 \\ \hline
        Yolo-9-e & 58.1 & 1620 & 15358 & **81.0** & **65.0** & **70.9** & **48.7** \\ \hline
        Yolo-10-n & 2.3 & 1620 & 15358 & 66.8 & 53.2 & 57.2 & 35.9 \\ \hline
        Yolo-10-s & 7.2 & 1620 & 15358 & 75.8 & 57.0 & 62.7 & 40.9 \\ \hline
        Yolo-10-m & 15.4 & 1620 & 15358 & 71.4 & 61.4 & 65.7 & 43.8 \\ \hline
        Yolo-10-b & 19.1 & 1620 & 15358 & 77.7 & 59.1 & 65.8 & 45.1 \\ \hline
        Yolo-10-l & 24.4 & 1620 & 15358 & 76.0 & 61.8 & 67.4 & 46.0 \\ \hline
        Yolo-10-x & 29.5 & 1620 & 15358 & 76.8 & 62.8 & 67.8 & 46.7 \\ \hline
    \end{tabular}
\end{table}

As can be seen the model performed terribly on the COCO metrics. 
One of the key reasons for the terrible metrics seems to be the excess prediction boxes being generated by the prediction code, and while these boxes do fall within the ground truth area as seen in Figure X, each is counted as a "person" class detection and thus skews metric calculation.

As described in the previous section, steps were taken to account for this such as NMS, box merging, and feature score threshold. 
Further improvements of the boxes post processing and hyper parameter tuning for the SGD optimizer could be done, but are beyond the scope of this report.
